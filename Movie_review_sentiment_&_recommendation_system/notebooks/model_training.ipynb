{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### check the GPU",
   "id": "30379641169162b6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-22T11:42:26.438049Z",
     "start_time": "2026-01-22T11:42:26.433853Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpu:\n",
    "  name = tf.config.experimental.get_device_details(gpu[0]).get(\"device_name\",\"unknow\")\n",
    "  print(\"CUDA available: TRUE\")\n",
    "  print(\"GPU name: \",name)\n",
    "else:\n",
    "  print(\"CUDA available: False\")\n",
    "  print(\"GPU: No GPU\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: TRUE\n",
      "GPU name:  NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. import",
   "id": "ed1ee977e6be8cbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T11:58:24.490877Z",
     "start_time": "2026-01-22T11:58:24.487586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer,TFAutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "# for model fit\n",
    "from transformers import TFAutoModel\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ],
   "id": "51288477d0e2e434",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. load the data",
   "id": "75fc6c79e2e8d7d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T11:58:56.776130Z",
     "start_time": "2026-01-22T11:58:52.420098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "train_ds = dataset[\"train\"]\n",
    "test_ds = dataset[\"test\"]"
   ],
   "id": "3b0ce05e0c0d0cc0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T12:00:32.122912Z",
     "start_time": "2026-01-22T12:00:32.061346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert to the pd\n",
    "train = train_ds.to_pandas()\n",
    "test = test_ds.to_pandas()"
   ],
   "id": "fba40eaf2903e9a4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T13:17:06.772351Z",
     "start_time": "2026-01-22T13:17:00.153366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ],
   "id": "a6ac90085632f6e5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T13:18:01.360044Z",
     "start_time": "2026-01-22T13:17:06.787222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_token_lengths(dataset, tokenizer):\n",
    "    lengths = []\n",
    "    for example in tqdm(dataset):\n",
    "        tokens = tokenizer(\n",
    "            example[\"text\"],\n",
    "            truncation=False,\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "        lengths.append(len(tokens[\"input_ids\"]))\n",
    "    return lengths\n",
    "\n",
    "train_lengths = compute_token_lengths(train_ds, tokenizer)\n"
   ],
   "id": "5f967738b8b3b5ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 25000/25000 [00:54<00:00, 458.14it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T13:18:01.425759Z",
     "start_time": "2026-01-22T13:18:01.417054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Max length:\", np.max(train_lengths))\n",
    "print(\"Average length:\", np.mean(train_lengths))\n",
    "print(\"Median length:\", np.median(train_lengths))\n",
    "print(\"95th percentile:\", np.percentile(train_lengths, 95))\n",
    "print(\"99th percentile:\", np.percentile(train_lengths, 99))\n"
   ],
   "id": "7993259005e97023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 3127\n",
      "Average length: 313.87132\n",
      "Median length: 233.0\n",
      "95th percentile: 806.0499999999993\n",
      "99th percentile: 1206.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d495d2854e488bfb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
